<!-- language: rtl -->
<div dir="rtl" align="right" >

در فصل قبل، به بررسی نحوه نصب ابزارهای مختلفی مانند **NiFi**، **Airflow**، **PostgreSQL** و **Elasticsearch** پرداختیم. در این فصل، یاد خواهید گرفت که چگونه از این ابزارها استفاده کنید. یکی از اساسی‌ترین وظایف در مهندسی داده، انتقال داده از یک فایل متنی به یک پایگاه داده است. در این فصل، شما با خواندن و نوشتن داده‌ها در قالب‌های مختلف متنی مانند **CSV** و **JSON** آشنا خواهید شد.

---

### موضوعات اصلی این فصل:
- خواندن و نوشتن فایل‌ها در Python
- پردازش فایل‌ها در Airflow
- پردازنده‌های NiFi برای مدیریت فایل‌ها
- خواندن و نوشتن داده‌ها در پایگاه‌های داده با Python
- پایگاه‌های داده در Airflow
- پردازنده‌های پایگاه داده در NiFi

---

### **نوشتن و خواندن فایل‌ها در Python**
عنوان این بخش ممکن است کمی عجیب به نظر برسد، زیرا معمولاً ابتدا خواندن و سپس نوشتن را می‌بینید. اما در اینجا، ابتدا داده‌ها را خواهید نوشت و سپس آن‌ها را خواهید خواند. با نوشتن داده‌ها، ساختار داده‌ها را درک خواهید کرد و مطمئن خواهید شد که دقیقاً چه چیزی قصد خواندن آن را دارید.

#### **استفاده از کتابخانه Faker برای تولید داده‌های جعلی:**
برای نوشتن داده‌ها، از کتابخانه‌ای به نام **Faker** استفاده خواهید کرد. **Faker** به شما اجازه می‌دهد داده‌های جعلی برای فیلدهای رایج ایجاد کنید. به عنوان مثال، می‌توانید یک آدرس با فراخوانی `address()` یا یک نام زنانه با استفاده از `name_female()` تولید کنید. این کار ساخت داده‌های جعلی را ساده‌تر می‌کند و در عین حال آن‌ها را واقع‌گرایانه‌تر می‌نماید.

برای نصب **Faker**، می‌توانید از دستور زیر استفاده کنید:
```bash
pip3 install faker
```

حالا که **Faker** نصب شده است، آماده نوشتن فایل‌ها هستید. در بخش بعدی، با فایل‌های **CSV** شروع خواهیم کرد.

---

### **نوشتن و خواندن فایل‌های CSV**
متداول‌ترین نوع فایلی که با آن مواجه خواهید شد، **Comma-Separated Values (CSV)** است. یک فایل CSV از فیلدهایی تشکیل شده است که با کاما جدا شده‌اند. از آنجایی که کاماها در متن‌ها بسیار متداول هستند، باید بتوانید آن‌ها را در فایل‌های CSV مدیریت کنید. این کار معمولاً با استفاده از کاراکترهای فرار (Escape Characters) انجام می‌شود که معمولاً شامل قرار دادن متن‌ها در داخل علامت‌های نقل قول (`"`) است. این نقل قول‌ها به عنوان کاراکترهای فرار شناخته می‌شوند. کتابخانه استاندارد Python برای مدیریت CSV، فرآیند کار با داده‌های CSV را ساده‌تر می‌کند.

---

#### **نوشتن فایل‌های CSV با استفاده از کتابخانه CSV در Python**
برای نوشتن یک فایل CSV با استفاده از کتابخانه CSV، باید مراحل زیر را دنبال کنید:

1. **باز کردن فایل در حالت نوشتن:**
   برای باز کردن یک فایل، باید یک نام فایل و یک حالت مشخص کنید. حالت نوشتن با `w` نشان داده می‌شود. همچنین می‌توانید فایل را برای خواندن با `r`، اضافه کردن با `a` یا خواندن و نوشتن با `r+` باز کنید. اگر با فایل‌های غیر متنی سروکار دارید، می‌توانید `b` (حالت باینری) را به هر یک از این حالت‌ها اضافه کنید. به عنوان مثال، `wb` به شما اجازه می‌دهد داده‌ها را به صورت بایت بنویسید:
   ```python
   output = open('myCSV.CSV', mode='w')
   ```

2. **ایجاد CSV_writer:**
   حداقل باید یک فایل برای نوشتن مشخص کنید، اما می‌توانید پارامترهای اضافی مانند **dialect** را نیز ارسال کنید. یک dialect می‌تواند نوع CSV تعریف‌شده‌ای مانند Excel باشد یا گزینه‌هایی مانند delimiter یا سطح quoting را مشخص کند. مقادیر پیش‌فرض معمولاً کافی هستند. برای مثال، delimiter به طور پیش‌فرض کاما است و quoting به طور پیش‌فرض `QUOTE_MINIMAL` است که فقط وقتی نقل قول اضافه می‌کند که کاراکترهای خاص یا delimiter در یک فیلد وجود داشته باشد:
   ```python
   mywriter = csv.writer(output)
   ```

3. **اضافه کردن Header:**
   شاید بتوانید به یاد داشته باشید که فیلدهای CSV شما چیستند، اما بهتر است یک header اضافه کنید. نوشتن header مشابه نوشتن هر ردیف دیگری است. ابتدا مقادیر را تعریف کنید و سپس از `writerow()` استفاده کنید:
   ```python
   header = ['name', 'age']
   mywriter.writerow(header)
   ```

4. **نوشتن داده‌ها در فایل:**
   حالا می‌توانید یک ردیف داده را با استفاده از `writerow()` بنویسید:
   ```python
   data = ['Bob Smith', 40]
   mywriter.writerow(data)
   output.close()
   ```
   اکنون اگر به دایرکتوری نگاه کنید، یک فایل CSV با نام `myCSV.CSV` خواهید داشت که محتوای آن باید شبیه تصویر زیر باشد.

---

#### **تولید 1,000 رکورد با Faker:**
در مثال زیر، از **Faker** برای تولید 1,000 رکورد استفاده خواهیم کرد:
```python
from faker import Faker
import csv

output = open('data.CSV', 'w')
fake = Faker()

header = ['name', 'age', 'street', 'city', 'state', 'zip', 'lng', 'lat']
mywriter = csv.writer(output)
mywriter.writerow(header)

for r in range(1000):
    mywriter.writerow([
        fake.name(),
        fake.random_int(min=18, max=80, step=1),
        fake.street_address(),
        fake.city(),
        fake.state(),
        fake.zipcode(),
        fake.longitude(),
        fake.latitude()
    ])

output.close()
```
اکنون باید یک فایل `data.CSV` با 1,000 ردیف از نام‌ها و سن‌ها داشته باشید.

---

### **خواندن فایل‌های CSV**
خواندن یک CSV تا حدودی مشابه نوشتن آن است. مراحل مشابهی دنبال می‌شود، اما با تغییرات جزئی:

1. **باز کردن فایل با استفاده از `with`:**
   استفاده از `with` مزایای اضافی دارد، اما برای حال حاضر، مهم‌ترین مزیت آن این است که نیازی به استفاده از `close()` ندارید. اگر حالتی مشخص نکنید، `open` به طور پیش‌فرض به حالت خواندن (`r`) تنظیم می‌شود:
   ```python
   with open('data.csv') as f:
   ```

2. **ایجاد Reader:**
   به جای استفاده از `reader()`، از `DictReader()` استفاده کنید. با استفاده از `DictReader`، می‌توانید فیلدها را با نام فراخوانی کنید و نیازی به استفاده از موقعیت آن‌ها نیست. برای مثال، به جای فراخوانی `row[0]`، می‌توانید از `row['name']` استفاده کنید:
   ```python
   myreader = csv.DictReader(f)
   ```

3. **گرفتن Headerها با خواندن یک خط با `next()`:**
   ```python
   headers = next(myreader)
   ```

4. **پیمایش بقیه ردیف‌ها:**
   ```python
   for row in myreader:
   ```

5. **چاپ نام‌ها:**
   ```python
   print(row['name'])
   ```

اکنون باید فقط 1,000 نام را ببینید که از صفحه می‌گذرند. حالا یک دیکشنری Python دارید که می‌توانید آن را به هر شکلی که نیاز دارید دستکاری کنید.

---

# **خواندن و نوشتن فایل‌های CSV با pandas DataFrame**  

**pandas DataFrame** ابزاری قدرتمند برای **خواندن، نوشتن، جستجو و پردازش داده‌ها** است. در حالی که **pandas** نسبت به **کتابخانه داخلی CSV** سربار بیشتری دارد، اما در بسیاری از موارد، ارزش استفاده را دارد.  

اگر pandas در محیط **Python** شما نصب نشده است، می‌توانید با دستور زیر آن را نصب کنید:  

```bash
pip3 install pandas
```

### **مفهوم DataFrame**  
یک **DataFrame** را می‌توان مانند یک **جدول در پایگاه داده** یا **برگه‌ای در Excel** در نظر گرفت که شامل **ردیف‌ها، ستون‌ها و یک شاخص (index)** است.  

---

### **۱. خواندن فایل CSV در pandas**  

برای بارگذاری یک **فایل CSV** در یک **DataFrame**، مراحل زیر را دنبال کنید:  

#### **گام ۱: وارد کردن pandas**  

```python
import pandas as pd
```

#### **گام ۲: خواندن فایل CSV با متد `read_csv()`**  

تابع `read_csv()` یک آرگومان ضروری (نام فایل) و چندین آرگومان اختیاری دارد. برخی از آرگومان‌های مهم شامل موارد زیر هستند:  

- **`header`**: به‌طور پیش‌فرض pandas سعی می‌کند هدر را تشخیص دهد. با `header=0` می‌توان هدر را از اولین ردیف در نظر گرفت.  
- **`names`**: اگر `header=None` باشد، می‌توان نام ستون‌ها را به‌صورت دستی تعیین کرد.  
- **`nrows`**: اگر فایل بزرگی دارید و فقط می‌خواهید بخشی از آن را بخوانید، این پارامتر مشخص می‌کند که چند ردیف خوانده شود.  

مثال:  

```python
df = pd.read_csv('data.csv')
```

#### **گام ۳: نمایش اولین ۱۰ رکورد از DataFrame**  

```python
df.head(10)
```

---

### **۲. ایجاد DataFrame در Python به‌صورت دستی**  

می‌توان یک **DataFrame** را مستقیماً در Python ایجاد کرد. برای این کار:  

#### **گام ۱: تعریف یک دیکشنری شامل داده‌ها**  

```python
data = {
    'Name': ['Paul', 'Bob', 'Susan', 'Yolanda'],
    'Age': [23, 45, 18, 21]
}
```

#### **گام ۲: تبدیل دیکشنری به DataFrame**  

```python
df = pd.DataFrame(data)
```

---

### **۳. نوشتن DataFrame در یک فایل CSV**  

برای ذخیره داده‌های DataFrame در یک فایل **CSV** از متد `to_csv()` استفاده کنید.  

```python
df.to_csv('fromdf.csv', index=False)
```

🔹 **توجه:**  
- اگر `index=False` تنظیم نشود، pandas به‌صورت پیش‌فرض یک ستون **ایندکس (۰ تا n)** اضافه می‌کند.  
- اگر نمی‌خواهید این مقدار در فایل CSV ذخیره شود، `index=False` را تنظیم کنید.  


# **نوشتن JSON با Python**  

**JSON (JavaScript Object Notation)** یکی از فرمت‌های رایج برای **ذخیره و انتقال داده‌ها** است. این فرمت را معمولاً هنگام تعامل با **APIها** مشاهده خواهید کرد، اما می‌تواند به‌عنوان یک فایل مستقل نیز ذخیره شود.  

Python دارای یک **کتابخانه استاندارد** برای پردازش JSON است که نام آن **json** است.

---

### **۱. نوشتن داده‌ها در یک فایل JSON**  

برای نوشتن داده‌ها در یک فایل JSON با استفاده از Python، مراحل زیر را دنبال کنید:  

#### **گام ۱: وارد کردن کتابخانه‌های مورد نیاز و باز کردن فایل JSON برای نوشتن**  

```python
from faker import Faker
import json

output = open('data.json', 'w')  # ایجاد فایل JSON برای نوشتن
fake = Faker()  # ساخت شیء Faker برای تولید داده‌های تصادفی
```

#### **گام ۲: ایجاد دیکشنری برای نگهداری داده‌ها**  

```python
alldata = {}  
alldata['records'] = []  # ایجاد کلید records با مقدار یک لیست خالی
```

#### **گام ۳: تولید ۱۰۰۰ رکورد و اضافه کردن به دیکشنری**  

```python
for x in range(1000):
    data = {
        "name": fake.name(),
        "age": fake.random_int(min=18, max=80, step=1),
        "street": fake.street_address(),
        "city": fake.city(),
        "state": fake.state(),
        "zip": fake.zipcode(),
        "lng": float(fake.longitude()),
        "lat": float(fake.latitude())
    }
    alldata['records'].append(data)  # افزودن رکورد جدید به لیست records
```

#### **گام ۴: ذخیره داده‌ها در فایل JSON**  

```python
json.dump(alldata, output)  # نوشتن دیکشنری alldata در فایل JSON
```

✅ اکنون فایل **`data.json`** شامل یک **آرایه (لیست) از ۱۰۰۰ رکورد** است.

---

### **۲. خواندن داده‌ها از فایل JSON**  

برای خواندن داده‌های ذخیره‌شده در فایل **JSON**، مراحل زیر را دنبال کنید:  

#### **گام ۱: باز کردن فایل برای خواندن**  

```python
with open("data.json", "r") as f:
```

#### **گام ۲: بارگذاری محتویات فایل JSON در متغیر**  

```python
    data = json.load(f)  # خواندن داده‌ها از فایل و ذخیره در متغیر data
```

#### **گام ۳: نمایش اولین رکورد از داده‌ها**  

```python
print(data['records'][0])  # نمایش اولین رکورد از لیست records
```

یا اگر فقط نام اولین شخص را می‌خواهید:

```python
print(data['records'][0]['name'])
```

---

### **نکات مهم درباره `json.load()` و `json.dump()`**  

✅ **`json.load()`** و **`json.dump()`** برای کار با **فایل‌ها** استفاده می‌شوند.  
✅ **`json.loads()`** و **`json.dumps()`** برای کار با **رشته‌های متنی JSON** استفاده می‌شوند و **سریال‌سازی انجام نمی‌دهند**.  

**تفاوت بین `load` و `loads`، `dump` و `dumps`:**  

| متد | کاربرد |
|------|---------|
| `json.load(f)` | خواندن JSON از یک **فایل** |
| `json.loads(s)` | تبدیل **رشته JSON** به **دیکشنری** |
| `json.dump(obj, f)` | نوشتن دیکشنری در یک **فایل JSON** |
| `json.dumps(obj)` | تبدیل **دیکشنری** به **رشته JSON** |

---


# **DataFrame در pandas و کار با JSON**  

خواندن و نوشتن **JSON** با **pandas DataFrame** بسیار شبیه به کار با **CSV** است. تنها تفاوت این است که به‌جای **`to_csv()`** از **`to_json()`** و به‌جای **`read_csv()`** از **`read_json()`** استفاده می‌کنید.

---

### **۱. خواندن یک فایل JSON ساده با pandas**  

اگر فایل **JSON** شما ساختار ساده و تمیزی داشته باشد، می‌توانید آن را مستقیماً در یک **DataFrame** بارگذاری کنید:  

```python
import pandas as pd

df = pd.read_json('data.json')
```

---

### **۲. خواندن JSON با ساختار پیچیده (Nested JSON)**  

در فایل **`data.json`**، اطلاعات درون یک **دیکشنری به نام `records`** قرار دارند. بنابراین، خواندن آن نیاز به چند مرحله اضافی دارد.

#### **گام ۱: وارد کردن کتابخانه JSON در pandas**  

```python
import pandas as pd
from pandas import json_normalize

```

#### **گام ۲: باز کردن و بارگذاری فایل JSON**  

```python
with open('data.json', 'r') as f:
    data = json.load(f)

# Normalize the nested JSON
df = json_normalize(data, max_level=1)
    
```

#### **گام ۳: نرمال‌سازی (تبدیل JSON به ساختار جدولی)**  

برای این کار از **`json_normalize()`** استفاده می‌کنیم تا داده‌ها از **`records`** استخراج شوند و به **DataFrame** تبدیل شوند:

```python
df = pd_JSON.json_normalize(data, record_path='records')
```

✅ اکنون **df** شامل تمام رکوردهای موجود در **`data.json`** است.

---

### **۳. ذخیره DataFrame به فایل JSON**  

می‌توانید **DataFrame** را دوباره در قالب **JSON** ذخیره کنید.  

#### **ذخیره با فرمت پیش‌فرض (`orient='columns'`)**  

```python
df.to_json('output.json')
```

خروجی مشابه زیر خواهد بود:  

```json
{
    "name": {"0": "Henry Lee", "1": "Corey Combs DDS"},
    "age": {"0": 42, "1": 43},
    "street": {"0": "57850 Zachary Camp", "1": "60066 Ruiz Plaza Apt. 752"},
    "city": {"0": "Lake Jonathon", "1": "East Kaitlin"},
    "state": {"0": "Rhode Island", "1": "Alabama"},
    "zip": {"0": "93363", "1": "16297"},
    "lng": {"0": -161.561209, "1": 123.894456},
    "lat": {"0": -72.086145, "1": -50.211986}
}
```

---

### **۴. ذخیره JSON در قالب `records` (ساختار خواناتر و مناسب برای پردازش در Airflow)**  

```python
df.to_json('output_records.json', orient='records', indent=4)
```

خروجی مشابه زیر خواهد بود:  

```json
[
    {
        "name": "Henry Lee",
        "age": 42,
        "street": "57850 Zachary Camp",
        "city": "Lake Jonathon",
        "state": "Rhode Island",
        "zip": "93363",
        "lng": -161.561209,
        "lat": -72.086145
    },
    {
        "name": "Corey Combs DDS",
        "age": 43,
        "street": "60066 Ruiz Plaza Apt. 752",
        "city": "East Kaitlin",
        "state": "Alabama",
        "zip": "16297",
        "lng": 123.894456,
        "lat": -50.211986
    }
]
```

✅ این ساختار **`records`** برای پردازش در ابزارهایی مانند **Apache Airflow** بسیار مناسب‌تر است.

---

### **۵. انواع فرمت‌های `orient` در `to_json()`**  

| مقدار `orient` | توضیح |
|--------------|------------|
| `columns` (پیش‌فرض) | داده‌ها را به‌صورت دیکشنری `{ستون: {ردیف: مقدار}}` ذخیره می‌کند. |
| `records` | هر ردیف را به‌صورت یک شیء JSON جداگانه ذخیره می‌کند. (مناسب برای **Airflow**) |
| `index` | داده‌ها را به‌صورت `{ردیف: {ستون: مقدار}}` ذخیره می‌کند. |
| `values` | فقط مقدارها را در قالب یک لیست تو در تو ذخیره می‌کند. |
| `table` | داده‌ها را در قالب JSON **استاندارد جدول‌محور** ذخیره می‌کند. |

✅ **برای پردازش داده‌ها در Airflow یا سایر سیستم‌های ETL، استفاده از `orient='records'` توصیه می‌شود.** 🚀